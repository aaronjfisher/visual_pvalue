<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Supplemental Code</title>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}

pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}
</style>



</head>

<body>
<h1>Supplemental Code</h1>

<p>This report was created using the knitr package (<a href="http://yihui.name/knitr/">http://yihui.name/knitr/</a>) in R (<a href="http://www.r-project.org/">http://www.r-project.org/</a>)</p>

<pre><code class="r">#Initial Setup
#Note: Output from this code section has been masked for the sake of saving space.

library(plotrix) 
library(lme4)

opts_chunk$set(dev = &#39;pdf&#39;)

#The code book for the two files below is included in the readMe files of the github repository.
x_full&lt;-read.csv(&#39;coursera_user_responses_tidy.csv&#39;,header=TRUE) #user responses to coursera questions.
load(&#39;data_for_1plots_coursera.RData&#39;)  #objects describing the library of plots shown to users.

logit&lt;-function(x) log(x/(1-x))
invLogit&lt;-function(x) {
  out&lt;-exp(x)/(1+exp(x)) #maintains the ability of the function to accept vectors
  out[exp(x)==Inf]&lt;-1
    return(out)
}
</code></pre>

<pre><code class="r">#Output from this section has been masked

#Process x_full

#re-order the style factor&#39;s levels so the reference category is first
uStyle&lt;-unique(c(&#39;n100ref&#39;,as.character(x_full$style)))
x_full$style&lt;-factor(as.character(x_full$style),levels=uStyle)
x_full$datVer&lt;- as.factor(as.numeric(x_full$datVer))
x_full$id&lt;- as.factor(as.numeric(x_full$id))
x_full$attemptNumFactor&lt;- as.factor(as.numeric(x_full$attemptNum))

#preview x_full
dim(x_full) #x_full includes everything, including missing data
head(x_full) #note: styleNum values 2 &amp; 3 are actually the same question style
lapply(x_full[1,],class)
N&lt;-sum(!is.na(x_full$guessSig))
n&lt;-sum(!duplicated(x_full$id[!is.na(x_full$guessSig)]))
K&lt;-length(uStyle)
N #total # responses
n #total # users
K #total # of question types

#Make a version without missing data
x&lt;- x_full[!is.na(x_full$guessSig),]

#Get number of answers for each question type
nStyle&lt;-c(table(x$style))[uStyle]
nStyle


uStyle
pretty_style_labels&lt;-c(&#39;Reference&#39;, &#39;Smaller n&#39;, &#39;Larger n&#39;, &#39;Best Fit&#39;,&#39;Axis Scale&#39;,
        &#39;Axis Label&#39;, &#39;Outlier&#39;, &#39;Lowess&#39;) #for use in plots


######### How many users finished their first attempts of the quiz
    ## this section is commented out, as it runs fairly slowly.
# userNames&lt;-unique(x$id)
# num_of_first_try_by_user&lt;-rep(NA,n)
# for(i in 1:n){
#   num_of_first_try_by_user[i]&lt;- sum(x$id==userNames[i] &amp; x$attemptNum==1)
# }
# mean(num_of_first_try_by_user==9) #=.944
#########
</code></pre>

<h2>Models for Baseline Accuracy, and Effect of Plot Presentation Style</h2>

<pre><code class="r">#Just look at first attempts of the survey
attemptNum1Data&lt;-x[x$attemptNum==1,]


#Using 2 separate models, one for sensitivity, one for specificity (sense &amp; spec)
sum(attemptNum1Data$trueSig) # number of responses used in sense model = 9063
</code></pre>

<pre><code>## [1] 9063
</code></pre>

<pre><code class="r">sum(!attemptNum1Data$trueSig) # number of responses used in spec model = 9032
</code></pre>

<pre><code>## [1] 9032
</code></pre>

<pre><code class="r">glmmSense &lt;- glmer(correct ~ 1 + (1|id) + (1|qNameCoursera) + style, 
  data=attemptNum1Data[attemptNum1Data$trueSig,],family=&quot;binomial&quot;) #Sensitivity model
glmmSpec &lt;- glmer(correct ~ 1 + (1|id) + (1|qNameCoursera) + style,
  data=attemptNum1Data[!attemptNum1Data$trueSig,],family=&quot;binomial&quot;) #Specificity model


### Show basic output
print(glmmSense,correlation=FALSE)
</code></pre>

<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: correct ~ 1 + (1 | id) + (1 | qNameCoursera) + style
##    Data: attemptNum1Data[attemptNum1Data$trueSig, ]
##      AIC      BIC   logLik deviance df.resid 
##    11896    11967    -5938    11876     9053 
## Random effects:
##  Groups        Name        Std.Dev.
##  id            (Intercept) 0.659   
##  qNameCoursera (Intercept) 0.371   
## Number of obs: 9063, groups:  id, 2036; qNameCoursera, 40
## Fixed Effects:
##    (Intercept)        stylen35       stylen200    stylebestFit  
##        -0.1165         -0.7954         -0.1085          0.5146  
## styleaxesScale  styleaxesLabel    styleoutlier     stylelowess  
##         0.3081          0.0347          1.0457          0.2589
</code></pre>

<pre><code class="r">print(glmmSpec,correlation=FALSE)
</code></pre>

<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: correct ~ 1 + (1 | id) + (1 | qNameCoursera) + style
##    Data: attemptNum1Data[!attemptNum1Data$trueSig, ]
##      AIC      BIC   logLik deviance df.resid 
##    10921    10993    -5451    10901     9022 
## Random effects:
##  Groups        Name        Std.Dev.
##  id            (Intercept) 0.799   
##  qNameCoursera (Intercept) 0.426   
## Number of obs: 9032, groups:  id, 2032; qNameCoursera, 40
## Fixed Effects:
##    (Intercept)        stylen35       stylen200    stylebestFit  
##          1.109           0.607          -1.160          -0.507  
## styleaxesScale  styleaxesLabel    styleoutlier     stylelowess  
##         -0.433          -0.219          -0.556          -0.389
</code></pre>

<pre><code class="r">#Get odds ratios and CIs for odds ratios
getORCIs&lt;-function(model){ 
  #logit(E(Y))=X*Beta; 
  #odds(E(Y))=exp(X*Beta)
  modelCoef&lt;-fixef(model)
  modelSe&lt;-sqrt(diag(vcov(model))) #std error
  fitted_OR&lt;-exp(modelCoef) 
  li&lt;- exp(modelCoef - qnorm(.975) * modelSe)
  ui&lt;- exp(modelCoef + qnorm(.975) * modelSe)

  out&lt;- signif(cbind(fitted_OR, li, ui),3)
  rownames(out)&lt;- pretty_style_labels
  kable(out)
}
</code></pre>

<p>Show odds ratios, CIs for odds ratios, and variance explained by random intercepts.</p>

<pre><code class="r"># 95% Confidence intervals = (li, ui)
getORCIs(glmmSense)
</code></pre>

<table><thead>
<tr>
<th align="left"></th>
<th align="right">fitted_OR</th>
<th align="right">li</th>
<th align="right">ui</th>
</tr>
</thead><tbody>
<tr>
<td align="left">Reference</td>
<td align="right">0.890</td>
<td align="right">0.633</td>
<td align="right">1.250</td>
</tr>
<tr>
<td align="left">Smaller n</td>
<td align="right">0.451</td>
<td align="right">0.276</td>
<td align="right">0.738</td>
</tr>
<tr>
<td align="left">Larger n</td>
<td align="right">0.897</td>
<td align="right">0.551</td>
<td align="right">1.460</td>
</tr>
<tr>
<td align="left">Best Fit</td>
<td align="right">1.670</td>
<td align="right">1.030</td>
<td align="right">2.730</td>
</tr>
<tr>
<td align="left">Axis Scale</td>
<td align="right">1.360</td>
<td align="right">0.834</td>
<td align="right">2.220</td>
</tr>
<tr>
<td align="left">Axis Label</td>
<td align="right">1.040</td>
<td align="right">0.635</td>
<td align="right">1.690</td>
</tr>
<tr>
<td align="left">Outlier</td>
<td align="right">2.850</td>
<td align="right">1.740</td>
<td align="right">4.650</td>
</tr>
<tr>
<td align="left">Lowess</td>
<td align="right">1.300</td>
<td align="right">0.795</td>
<td align="right">2.110</td>
</tr>
</tbody></table>

<pre><code class="r">getORCIs(glmmSpec)
</code></pre>

<table><thead>
<tr>
<th align="left"></th>
<th align="right">fitted_OR</th>
<th align="right">li</th>
<th align="right">ui</th>
</tr>
</thead><tbody>
<tr>
<td align="left">Reference</td>
<td align="right">3.030</td>
<td align="right">2.050</td>
<td align="right">4.480</td>
</tr>
<tr>
<td align="left">Smaller n</td>
<td align="right">1.840</td>
<td align="right">1.040</td>
<td align="right">3.230</td>
</tr>
<tr>
<td align="left">Larger n</td>
<td align="right">0.314</td>
<td align="right">0.180</td>
<td align="right">0.547</td>
</tr>
<tr>
<td align="left">Best Fit</td>
<td align="right">0.602</td>
<td align="right">0.345</td>
<td align="right">1.050</td>
</tr>
<tr>
<td align="left">Axis Scale</td>
<td align="right">0.649</td>
<td align="right">0.372</td>
<td align="right">1.130</td>
</tr>
<tr>
<td align="left">Axis Label</td>
<td align="right">0.804</td>
<td align="right">0.460</td>
<td align="right">1.400</td>
</tr>
<tr>
<td align="left">Outlier</td>
<td align="right">0.573</td>
<td align="right">0.329</td>
<td align="right">1.000</td>
</tr>
<tr>
<td align="left">Lowess</td>
<td align="right">0.678</td>
<td align="right">0.388</td>
<td align="right">1.180</td>
</tr>
</tbody></table>

<pre><code class="r">#Show variance explained by the random intercepts in each model
#Works specifically for binomial models
get_var_explained_by_rand_int&lt;-function(model){
  G&lt;-unlist(lapply(
      (VarCorr(model)),
      function(x)attr(x,&#39;stddev&#39;)
    ))^2
  return( G/(sum(G)+(pi^2)/3) )
}

# get_var_explained_by_rand_int(glmmInt)
get_var_explained_by_rand_int(glmmSense)
</code></pre>

<pre><code>       id.(Intercept) qNameCoursera.(Intercept) 
              0.11251                   0.03571 
</code></pre>

<pre><code class="r">get_var_explained_by_rand_int(glmmSpec)
</code></pre>

<pre><code>       id.(Intercept) qNameCoursera.(Intercept) 
              0.15543                   0.04424 
</code></pre>

<p>Recreate two examples of plots shown to users.</p>

<pre><code class="r">par(mar=c(3,3.5,3,0),oma=c(1,.5,0,1),mfcol=c(1,2))

#Make example plots from the reference category, one significant and one not
plotSigRefInd&lt;-which(pres==&#39;n100ref&#39;&amp;pvals&lt;.05)[4]
plotNotSigRefInd&lt;-which(pres==&#39;n100ref&#39;&amp;pvals&gt;=.05)[4]

plot(xes[plotSigRefInd,],yes[plotSigRefInd,],xlab=&#39;&#39;,ylab=&#39;&#39;)
mtext(paste0(&#39;Example: Truly Significant Plot\n(p=&#39;,round(pvals[plotSigRefInd],3),&#39;)&#39;),
  3,line=.4,font=2,cex=1.2)
mtext(&#39;X&#39;,1,line=2)
mtext(&#39;Y&#39;,2,line=2.5)
mtext(&#39;A)&#39;,3,line=1.5,adj=0,font=2,cex=1.2)

plot(xes[plotNotSigRefInd,],yes[plotNotSigRefInd,],xlab=&#39;&#39;,ylab=&#39;&#39;)
mtext(paste0(&#39;Example: Non-significant Plot\n(p=&#39;,round(pvals[plotNotSigRefInd],3),&#39;)&#39;),3,line=.4,
  font=2,cex=1.2)
mtext(&#39;X&#39;,1,line=2)
mtext(&#39;B)&#39;,3,line=1.5,adj=0,font=2,cex=1.2)
</code></pre>

<p><img src="data:application/pdf;base64,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" alt="plot of chunk example_ref_plots"/> </p>

<p>Get confidence intervals on accuracy scale, as opposed to odds ratio scale, and plot results.</p>

<pre><code class="r">#Function for generating confidence intervals for the fitted accuracy rates for each plot style;
#This function is meant to be used separately, for both the sensitivity and specificity models
getCIs&lt;-function(model=glmmSense, plotInd=1:K, ci_width_scalar=1.96, plotIt=TRUE,
    axisLab=TRUE, cex.axis=1, offset=0, ref_lwd=2, ...){ #y can also be specificity
  #diag(vcov(model))
    #fixef(model)

    coefNames&lt;-rep(NA,K)
    coefNames[1]&lt;-&#39;(Intercept)&#39;
    coefNames[2:K]&lt;-levels(x$style)[-1]
    modelCoef&lt;-fixef(model)
    names(modelCoef)&lt;-coefNames

    ui&lt;- #upper CI (on probability/accuracy scale)
    li&lt;- # Lower CI
    center&lt;-rep(NA,8)
    for(k in 1:K){
        #let a be the vector such that crossprod(a,modelCoef) = intercept + coefficient[k]
        #abbreviate this crossproduct as &#39;af&#39;
        a&lt;-rep(0,K)
        names(a)&lt;-coefNames
        a[&#39;(Intercept)&#39;]&lt;-1
        if(k&gt;1) a[coefNames[k]]&lt;-1
        var_af&lt;- t(a) %*% vcov(model) %*% a
        se_af&lt;-sqrt(as.numeric(var_af))
        center_logOdds &lt;- t(a)%*%modelCoef
        ui[k]&lt;- invLogit( center_logOdds + ci_width_scalar*se_af)
        li[k]&lt;- invLogit( center_logOdds - ci_width_scalar*se_af)
        center[k]&lt;- invLogit(center_logOdds)
    }   

    if(plotIt){
        plotCI(x=center[plotInd]*100,y=offset+(length(plotInd)):1,ui=ui[plotInd]*100,
            li=li[plotInd]*100,pch=19,cex=.5,yaxt=&#39;n&#39;,err=&#39;x&#39;,ylab=&#39;&#39;, ...)
        if(axisLab) axis(2, at=1:(length(plotInd)), labels=pretty_style_labels[plotInd][(length(plotInd)):1],
            cex.axis=cex.axis,las=2) #need to reorder labels so they go down, not up
        abline(v=center[1]*100,lty=2,lwd=ref_lwd)
    }

    out&lt;- cbind(center,ui,li)
    rownames(out)&lt;- pretty_style_labels
    return(kable(out))
}


#plot confidence intervals for fitted accuracy
par(oma=c(0,4,0,0))
plotInd4CIfig_pre&lt;-c(1,order(fixef(glmmSense)[-1])+1) #order plots by sense coef, not including ref category
plotInd4CIfig&lt;-plotInd4CIfig_pre[plotInd4CIfig_pre!=7] #dropping outlier from plot
getCIs(glmmSense,plotInd=plotInd4CIfig,col=c(&quot;darkblue&quot;),main=&#39;&#39;,xlab=&#39;&#39;,xlim=c(0,100),
    cex.axis=1.1,lwd=2,offset=.125,ylim=c(.8,7.2))
</code></pre>

<table><thead>
<tr>
<th align="left"></th>
<th align="right">center</th>
<th align="right">ui</th>
<th align="right">li</th>
</tr>
</thead><tbody>
<tr>
<td align="left">Reference</td>
<td align="right">0.4709</td>
<td align="right">0.5556</td>
<td align="right">0.3878</td>
</tr>
<tr>
<td align="left">Smaller n</td>
<td align="right">0.2866</td>
<td align="right">0.3647</td>
<td align="right">0.2195</td>
</tr>
<tr>
<td align="left">Larger n</td>
<td align="right">0.4440</td>
<td align="right">0.5319</td>
<td align="right">0.3594</td>
</tr>
<tr>
<td align="left">Best Fit</td>
<td align="right">0.5982</td>
<td align="right">0.6797</td>
<td align="right">0.5110</td>
</tr>
<tr>
<td align="left">Axis Scale</td>
<td align="right">0.5477</td>
<td align="right">0.6332</td>
<td align="right">0.4594</td>
</tr>
<tr>
<td align="left">Axis Label</td>
<td align="right">0.4795</td>
<td align="right">0.5673</td>
<td align="right">0.3930</td>
</tr>
<tr>
<td align="left">Outlier</td>
<td align="right">0.7169</td>
<td align="right">0.7835</td>
<td align="right">0.6393</td>
</tr>
<tr>
<td align="left">Lowess</td>
<td align="right">0.5355</td>
<td align="right">0.6215</td>
<td align="right">0.4474</td>
</tr>
</tbody></table>

<pre><code class="r">mtext(&#39;% Accuracy&#39;, side=1, line=2,cex=1.1)
mtext(&#39;Accuracy of Significance Classifications&#39;, side=3, line=.4,cex=1.2,font=2)
getCIs(glmmSpec,plotInd=plotInd4CIfig,col=c(&quot;darkred&quot;),axisLab=FALSE,main=&#39;&#39;,xlab=&#39;&#39;,
    xlim=c(0,100),lwd=2,add=TRUE,offset=-.125)
</code></pre>

<table><thead>
<tr>
<th align="left"></th>
<th align="right">center</th>
<th align="right">ui</th>
<th align="right">li</th>
</tr>
</thead><tbody>
<tr>
<td align="left">Reference</td>
<td align="right">0.7520</td>
<td align="right">0.8175</td>
<td align="right">0.6724</td>
</tr>
<tr>
<td align="left">Smaller n</td>
<td align="right">0.8477</td>
<td align="right">0.8938</td>
<td align="right">0.7863</td>
</tr>
<tr>
<td align="left">Larger n</td>
<td align="right">0.4873</td>
<td align="right">0.5866</td>
<td align="right">0.3890</td>
</tr>
<tr>
<td align="left">Best Fit</td>
<td align="right">0.6462</td>
<td align="right">0.7317</td>
<td align="right">0.5502</td>
</tr>
<tr>
<td align="left">Axis Scale</td>
<td align="right">0.6629</td>
<td align="right">0.7458</td>
<td align="right">0.5686</td>
</tr>
<tr>
<td align="left">Axis Label</td>
<td align="right">0.7090</td>
<td align="right">0.7848</td>
<td align="right">0.6194</td>
</tr>
<tr>
<td align="left">Outlier</td>
<td align="right">0.6348</td>
<td align="right">0.7220</td>
<td align="right">0.5379</td>
</tr>
<tr>
<td align="left">Lowess</td>
<td align="right">0.6727</td>
<td align="right">0.7544</td>
<td align="right">0.5790</td>
</tr>
</tbody></table>

<pre><code class="r">abline(v=seq(0,100,by=20),col=&#39;darkgray&#39;,lty=2,lwd=2)
legend(&#39;bottomleft&#39;,c(&#39;Sensitivity&#39;, &#39;Specificity&#39;),col=c(&#39;darkblue&#39;,&#39;darkred&#39;),pch=19,bg=&#39;white&#39;)
</code></pre>

<p><img src="data:application/pdf;base64,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" alt="plot of chunk accuracy_CIs"/> </p>

<h2>Models for Learning</h2>

<pre><code class="r">#select users who did the survey at least twice, but exclude questions they saw twice.
users_with_multiple_tries&lt;- unique(x$id[x$attemptNum&gt;1])
multi_try_data_ind&lt;-x$id %in% users_with_multiple_tries 
multi_try_data&lt;-x[multi_try_data_ind&amp; x$firstTry,]

#Calculate the percent of second attempts were discarded because users saw a duplicate plot
1-sum(multi_try_data_ind&amp; x$firstTry)/sum(multi_try_data_ind)
</code></pre>

<pre><code>## [1] 0.1279
</code></pre>

<pre><code class="r">########  Of users with multiple attempts, how many compeleted their first &amp; second attempts?
userNames2&lt;-unique(x[multi_try_data_ind,&#39;id&#39;])
multi_users_1st_tries&lt;-
multi_users_2nd_tries&lt;-rep(NA,length(userNames2))
for(i in 1:length(userNames2)){
  multi_users_2nd_tries[i]&lt;- sum(x[multi_try_data_ind,&#39;id&#39;]==userNames2[i] &amp;
    x[multi_try_data_ind,&#39;attemptNum&#39;]==2)
  multi_users_1st_tries[i]&lt;- sum(x[multi_try_data_ind,&#39;id&#39;]==userNames2[i] &amp; 
    x[multi_try_data_ind,&#39;attemptNum&#39;]==1)
}
mean(multi_users_1st_tries==9) #=.92
</code></pre>

<pre><code>## [1] 0.9208
</code></pre>

<pre><code class="r">mean(multi_users_2nd_tries==9) #=.99
</code></pre>

<pre><code>## [1] 0.9901
</code></pre>

<pre><code class="r">########


cut=2 #cutoff point for max # of tries in our model (only look at first and second attempts)
multi_try_data_sense_leq_cut&lt;- multi_try_data[multi_try_data$attemptNum&lt;=cut &amp; multi_try_data$trueSig,]
multi_try_data_spec_leq_cut &lt;- multi_try_data[multi_try_data$attemptNum&lt;=cut &amp; !multi_try_data$trueSig,]

#Fit random intercept model
dim(multi_try_data_sense_leq_cut) #846 = # responses in model
</code></pre>

<pre><code>## [1] 846  15
</code></pre>

<pre><code class="r">glmmSenseLearn_rIntercept = glmer(correct~ 1 +  (1|id)+ (1|qNameCoursera) + attemptNumFactor*style,
  data=multi_try_data_sense_leq_cut, family=&quot;binomial&quot;) # Fit model with interaction terms
</code></pre>

<pre><code>## Warning: Model failed to converge with max|grad| = 0.00142253 (tol =
## 0.001, component 17)
</code></pre>

<pre><code class="r">print(glmmSenseLearn_rIntercept,correlation=FALSE)
</code></pre>

<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## correct ~ 1 + (1 | id) + (1 | qNameCoursera) + attemptNumFactor *  
##     style
##    Data: multi_try_data_sense_leq_cut
##      AIC      BIC   logLik deviance df.resid 
##   1133.0   1218.4   -548.5   1097.0      828 
## Random effects:
##  Groups        Name        Std.Dev.
##  id            (Intercept) 0.385   
##  qNameCoursera (Intercept) 0.126   
## Number of obs: 846, groups:  id, 101; qNameCoursera, 40
## Fixed Effects:
##                      (Intercept)                 attemptNumFactor2  
##                           -0.477                             1.668  
##                         stylen35                         stylen200  
##                           -1.236                             0.417  
##                     stylebestFit                    styleaxesScale  
##                            0.221                             0.399  
##                   styleaxesLabel                      styleoutlier  
##                            0.225                             0.952  
##                      stylelowess        attemptNumFactor2:stylen35  
##                            0.727                            -0.162  
##      attemptNumFactor2:stylen200    attemptNumFactor2:stylebestFit  
##                           -1.322                            -0.578  
## attemptNumFactor2:styleaxesScale  attemptNumFactor2:styleaxesLabel  
##                           -0.995                            -1.537  
##   attemptNumFactor2:styleoutlier     attemptNumFactor2:stylelowess  
##                           -1.714                            -2.063
</code></pre>

<pre><code class="r">dim(multi_try_data_spec_leq_cut) #859 = # responses in model
</code></pre>

<pre><code>## [1] 859  15
</code></pre>

<pre><code class="r">glmmSpecLearn_rIntercept = glmer(correct ~ 1 +  (1|id) + (1|qNameCoursera)+ attemptNumFactor*style,
    data=multi_try_data_spec_leq_cut, family=&quot;binomial&quot;) #
</code></pre>

<pre><code>## Warning: Model failed to converge with max|grad| = 0.00306378 (tol =
## 0.001, component 10)
</code></pre>

<pre><code class="r">print(glmmSpecLearn_rIntercept,correlation=FALSE) 
</code></pre>

<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: 
## correct ~ 1 + (1 | id) + (1 | qNameCoursera) + attemptNumFactor *  
##     style
##    Data: multi_try_data_spec_leq_cut
##      AIC      BIC   logLik deviance df.resid 
##   1153.1   1238.7   -558.5   1117.1      841 
## Random effects:
##  Groups        Name        Std.Dev.
##  id            (Intercept) 0.669   
##  qNameCoursera (Intercept) 0.205   
## Number of obs: 859, groups:  id, 101; qNameCoursera, 40
## Fixed Effects:
##                      (Intercept)                 attemptNumFactor2  
##                          0.76381                          -0.00443  
##                         stylen35                         stylen200  
##                          0.96816                          -1.43606  
##                     stylebestFit                    styleaxesScale  
##                         -0.69900                          -0.83150  
##                   styleaxesLabel                      styleoutlier  
##                         -0.11459                          -0.25553  
##                      stylelowess        attemptNumFactor2:stylen35  
##                         -0.79142                          -1.84912  
##      attemptNumFactor2:stylen200    attemptNumFactor2:stylebestFit  
##                          0.81550                           0.30729  
## attemptNumFactor2:styleaxesScale  attemptNumFactor2:styleaxesLabel  
##                         -0.01431                          -0.64938  
##   attemptNumFactor2:styleoutlier     attemptNumFactor2:stylelowess  
##                         -0.73732                           0.04972
</code></pre>

<pre><code class="r">#Show variance explained by random intercepts
get_var_explained_by_rand_int(glmmSenseLearn_rIntercept)
</code></pre>

<pre><code>##            id.(Intercept) qNameCoursera.(Intercept) 
##                  0.042829                  0.004566
</code></pre>

<pre><code class="r">get_var_explained_by_rand_int(glmmSpecLearn_rIntercept)
</code></pre>

<pre><code>##            id.(Intercept) qNameCoursera.(Intercept) 
##                   0.11837                   0.01117
</code></pre>

<pre><code class="r">#Get CIs for learning models
# Get confidence intervals for the fitted accuracy rates for each combination of style and 
# attempt number in the learning model. 
# Also get confidence intervals for odds ratios for the learning effect in each category.
# To get interpretation of effect of attemptNum, we need to add attemptNum coeff to interaction terms. 
# Negative interaction just means that the learning effect is less strong than in the reference category.
# The function below returns a list of CI matrixes for each style, with rows for attemptNum.
getCIlearn&lt;-function(model,ci_width_scalar=1.96,test_type=&#39;two_sided&#39;){    

    modelCoef&lt;-fixef(model)
    coefNames&lt;-names(modelCoef)

    #find value of &#39;cut&#39; (max attemptNum in model)
    cut=length(coefNames)/K #K = number of categories for each attemptNum

    #list output by style
    CImats&lt;-list()

    for(k in 1:K){
        k_mat&lt;-matrix(NA,cut,8)
        colnames(k_mat)&lt;-c(&#39;centerProb&#39;,&#39;liProb&#39;,&#39;uiProb&#39;,&#39;centerOR&#39;,&#39;liOR&#39;,
            &#39;uiOR&#39;,&#39;zstat&#39;,&#39;p_value&#39;) #we&#39;ll add this to CImats later
        #attemptNum is the row index of k_mat
        for(no in 1:cut){
      # let a be the vector such that a&#39;modelCoef = intercept + coefficient k
            #abbreviate this t(a)%*%modelCoef as af

            a&lt;-rep(0,times=length(coefNames))
            names(a)&lt;-coefNames
            a[&#39;(Intercept)&#39;]&lt;-1
            if(k&gt;1) a[paste0(&#39;style&#39;,uStyle[k])] &lt;-1
            if(no&gt;1) a[paste0(&#39;attemptNumFactor&#39;,no)]&lt;-1
            if(k&gt;1 &amp; no&gt;1) a[paste0(&#39;attemptNumFactor&#39;,no,&#39;:style&#39;,uStyle[k])]  &lt;-1

            var_af&lt;- t(a) %*% vcov(model) %*% a
            se_af&lt;-sqrt(as.numeric(var_af))

            center_logOdds &lt;- crossprod(a,modelCoef)
            k_mat[no,&#39;uiProb&#39;]&lt;- invLogit( center_logOdds + ci_width_scalar*se_af)
            k_mat[no,&#39;liProb&#39;]&lt;- invLogit( center_logOdds - ci_width_scalar*se_af)
            k_mat[no,&#39;centerProb&#39;]&lt;- invLogit(center_logOdds)


            # pvalues need to be calculated the same way, but without the intercept term,
            # and without the baseline style term.
            # Get dist of &quot;wf&quot;=t(w)%*%coefficients, where w is a vector similar to &quot;a&quot;, above.
            if(no==1) next #This not relevant if a attemptNum=1

            w&lt;-rep(0,times=length(coefNames))
      names(w)&lt;-coefNames
      w[paste0(&#39;attemptNumFactor&#39;,no)]&lt;-1
            if(k&gt;1) w[paste0(&#39;attemptNumFactor&#39;,no,&#39;:style&#39;,uStyle[k])] &lt;-1

            var_wf&lt;-t(w) %*% vcov(model) %*% w
            se_wf&lt;-sqrt(as.numeric(var_wf))

      k_mat[no,&#39;centerOR&#39;]&lt;- exp(crossprod(w,modelCoef))
      k_mat[no,&#39;uiOR&#39;]&lt;- exp( crossprod(w,modelCoef) + ci_width_scalar*se_wf)
        k_mat[no,&#39;liOR&#39;]&lt;- exp( crossprod(w,modelCoef) - ci_width_scalar*se_wf)

            zstat&lt;- t(w)%*%modelCoef / se_wf
            if(test_type==&quot;two_sided&quot;)      p_value&lt;- 2*(1-pnorm(abs(zstat)))
            if(test_type==&quot;one_sided_up&quot;)   p_value&lt;-   (1-pnorm(zstat))
            if(test_type==&quot;one_sided_down&quot;) p_value&lt;-      pnorm(zstat)
            k_mat[no,&#39;zstat&#39;]&lt;- zstat
            k_mat[no,&#39;p_value&#39;]&lt;- p_value

        }
        CImats[[ uStyle[k] ]]&lt;-k_mat
    }
    return(CImats)
}

#Show confidence intervals for odds ratios regarding the learning effect, for each category.
getCIlearn(glmmSenseLearn_rIntercept) 
</code></pre>

<pre><code>## $n100ref
##      centerProb liProb uiProb centerOR  liOR  uiOR zstat   p_value
## [1,]     0.3831 0.2875 0.4886       NA    NA    NA    NA        NA
## [2,]     0.7671 0.6521 0.8527    5.304 2.675 10.52 4.779 1.766e-06
## 
## $n35
##      centerProb  liProb uiProb centerOR  liOR  uiOR zstat  p_value
## [1,]     0.1528 0.07892 0.2752       NA    NA    NA    NA       NA
## [2,]     0.4486 0.31018 0.5955    4.511 1.774 11.47 3.164 0.001558
## 
## $n200
##      centerProb liProb uiProb centerOR   liOR  uiOR  zstat p_value
## [1,]     0.4850 0.3473 0.6250       NA     NA    NA     NA      NA
## [2,]     0.5711 0.4078 0.7202    1.414 0.6038 3.309 0.7975  0.4252
## 
## $bestFit
##      centerProb liProb uiProb centerOR  liOR  uiOR zstat p_value
## [1,]     0.4364 0.2974 0.5861       NA    NA    NA    NA      NA
## [2,]     0.6973 0.5494 0.8132    2.975 1.264 7.003 2.497 0.01253
## 
## $axesScale
##      centerProb liProb uiProb centerOR   liOR  uiOR zstat p_value
## [1,]     0.4807 0.3491 0.6150       NA     NA    NA    NA      NA
## [2,]     0.6449 0.4889 0.7751    1.962 0.8627 4.461 1.608  0.1079
## 
## $axesLabel
##      centerProb liProb uiProb centerOR   liOR  uiOR  zstat p_value
## [1,]     0.4376 0.2989 0.5868       NA     NA    NA     NA      NA
## [2,]     0.4702 0.3099 0.6369    1.141 0.4677 2.782 0.2894  0.7723
## 
## $outlier
##      centerProb liProb uiProb centerOR   liOR  uiOR   zstat p_value
## [1,]     0.6168 0.4627 0.7506       NA     NA    NA      NA      NA
## [2,]     0.6061 0.4586 0.7365   0.9558 0.4106 2.225 -0.1049  0.9164
## 
## $lowess
##      centerProb liProb uiProb centerOR liOR  uiOR  zstat p_value
## [1,]     0.5622 0.4129 0.7010       NA   NA    NA     NA      NA
## [2,]     0.4639 0.3181 0.6162    0.674 0.29 1.566 -0.917  0.3591
</code></pre>

<pre><code class="r">getCIlearn(glmmSpecLearn_rIntercept)
</code></pre>

<pre><code>## $n100ref
##      centerProb liProb uiProb centerOR   liOR uiOR    zstat p_value
## [1,]     0.6822 0.5669 0.7787       NA     NA   NA       NA      NA
## [2,]     0.6812 0.5587 0.7830   0.9956 0.5216  1.9 -0.01344  0.9893
## 
## $n35
##      centerProb liProb uiProb centerOR    liOR   uiOR  zstat   p_value
## [1,]     0.8497 0.7101 0.9288       NA      NA     NA     NA        NA
## [2,]     0.4696 0.3108 0.6348   0.1567 0.05577 0.4402 -3.517 0.0004367
## 
## $n200
##      centerProb liProb uiProb centerOR   liOR  uiOR zstat p_value
## [1,]     0.3380 0.2060 0.5011       NA     NA    NA    NA      NA
## [2,]     0.5346 0.3766 0.6860     2.25 0.9304 5.443   1.8 0.07186
## 
## $bestFit
##      centerProb liProb uiProb centerOR   liOR  uiOR zstat p_value
## [1,]     0.5162 0.3629 0.6665       NA     NA    NA    NA      NA
## [2,]     0.5909 0.4228 0.7402    1.354 0.5655 3.241  0.68  0.4965
## 
## $axesScale
##      centerProb liProb uiProb centerOR   liOR  uiOR    zstat p_value
## [1,]     0.4831 0.3174 0.6526       NA     NA    NA       NA      NA
## [2,]     0.4784 0.3303 0.6304   0.9814 0.4073 2.365 -0.04177  0.9667
## 
## $axesLabel
##      centerProb liProb uiProb centerOR   liOR  uiOR  zstat p_value
## [1,]     0.6568 0.4987 0.7865       NA     NA    NA     NA      NA
## [2,]     0.4989 0.3491 0.6488   0.5201 0.2233 1.211 -1.516  0.1296
## 
## $outlier
##      centerProb liProb uiProb centerOR   liOR  uiOR  zstat p_value
## [1,]     0.6244 0.4649 0.7608       NA     NA    NA     NA      NA
## [2,]     0.4419 0.2814 0.6155   0.4763 0.1913 1.186 -1.594   0.111
## 
## $lowess
##      centerProb liProb uiProb centerOR   liOR  uiOR  zstat p_value
## [1,]     0.4931 0.3421 0.6454       NA     NA    NA     NA      NA
## [2,]     0.5044 0.3513 0.6567    1.046 0.4537 2.413 0.1062  0.9154
</code></pre>

<p>Display results for learning.</p>

<pre><code class="r">#Plotting (CIs for accuracy)
plot_LearnCImats&lt;-function(ciMat, plotStyle=&#39;n100ref&#39;, type=&#39;sense&#39;, data=multi_try_data,
        offset=0, cex.axis=1.1, add=FALSE, ...){
    cut&lt;-dim(ciMat)[1]
    thickness&lt;-c(2,2)


    plotCI(x=ciMat[,&#39;centerProb&#39;], y=1:cut+offset, ui=ciMat[,&#39;uiProb&#39;], li=ciMat[,&#39;liProb&#39;],
        err=&#39;x&#39;, pch=19, cex=.5, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;, lwd=thickness, xlim=c(-.05,1.05),
        ylim=c(.7,cut+.3), add=add, ...)
    if(add==FALSE){
    #need to reorder labels so they go down, not up
    axis(2, at=(1:cut), labels=1:cut,cex.axis=cex.axis) 
    xLabels&lt;-seq(0,1,length=6)
    #need to reorder labels so they go down, not up
    axis(1, at=xLabels, labels=xLabels*100,cex.axis=cex.axis) 
    abline(v=seq(0,1,by=.2),lty=2,lwd=2,col=&#39;darkgray&#39;) 
    mtext(text=&#39;Attempt\nNumber&#39;,side=2,line=2.25,cex=cex.axis)
  }
}



ciMat_learn_sense &lt;- getCIlearn(glmmSenseLearn_rIntercept)
ciMat_learn_spec  &lt;- getCIlearn(glmmSpecLearn_rIntercept)




par(mfrow=c(3,1),mar=c(2,7,3,1),oma=c(3,0,0,0))

#REFERENCE
plot_LearnCImats(ciMat_learn_sense[[&#39;n100ref&#39;]],col=&#39;darkblue&#39;,plotStyle=&#39;n100ref&#39;,
    type=&#39;sense&#39;,xlab=&#39;&#39;,ylab=&#39;&#39;,offset=.125)
plot_LearnCImats(ciMat_learn_spec[[&#39;n100ref&#39;]],main=&#39;&#39;,col=&#39;darkred&#39;,
    plotStyle=&#39;n100ref&#39;,type=&#39;spec&#39;,xlab=&#39;&#39;,add=TRUE,offset=-.125)
mtext(text=&#39;Reference&#39;,side=3,line=.4,cex=1.2,font=2)

legend(&#39;topleft&#39;,c(&#39;Sensitivity&#39;, &#39;Specificity&#39;),col=c(&#39;darkblue&#39;,&#39;darkred&#39;),
    pch=19,cex=1.4,bg=&#39;white&#39;)

#SMALL N
plot_LearnCImats(ciMat_learn_sense[[&#39;n35&#39;]],col=&#39;darkblue&#39;,plotStyle=&#39;n35&#39;,
    type=&#39;sense&#39;,ylab=&#39;&#39;,xlab=&#39;&#39;,offset=.125)
plot_LearnCImats(ciMat_learn_spec[[&#39;n35&#39;]],main=&#39;&#39;,col=&#39;darkred&#39;,
    plotStyle=&#39;n35&#39;,type=&#39;spec&#39;,xlab=&#39;&#39;,ylab=&#39;&#39;,offset=-.125,add=TRUE)
mtext(text=&#39;Smaller n&#39;,side=3,line=.4,cex=1.2,font=2)

#BEST FIT
plot_LearnCImats(ciMat_learn_sense[[&#39;bestFit&#39;]],col=&#39;darkblue&#39;,ylab=&#39;&#39;,
    xlab=&#39;&#39;,plotStyle=&#39;bestFit&#39;,type=&#39;sense&#39;,offset=.125)
plot_LearnCImats(ciMat_learn_spec[[&#39;bestFit&#39;]],main=&#39;&#39;,col=&#39;darkred&#39;,
    plotStyle=&#39;bestFit&#39;,type=&#39;spec&#39;,xlab=&#39;&#39;,offset=-.125,add=TRUE)
mtext(text=&#39;Best Fit&#39;,side=3,line=.4,cex=1.2,font=2)

mtext(text=&#39;% Accuracy&#39;,side=1,line=3,cex=1.1)
</code></pre>

<p><img src="data:application/pdf;base64,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" alt="plot of chunk learning_accuracy"/> </p>

</body>

</html>
